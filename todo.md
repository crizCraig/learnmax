- ~~Pass the action in as an embedding~~
  - Learn new state embedding so that the embedding can change to adapt with the added position embedding
  - ~~Understand why recent ViT models don't use the position encoding~~ (they just use conv for position)
  - ~~Try summing it with the state just like the position embedding~~
- ~~since loss is not decreasing, we should try to overfit on a single batch~~
- ~~visualize actual states and predicted states. right now we are not searching through a tree, so we should just be playing random actions and predicting the latent state results.~~
- ~~integrate transformer to take actions~~
- Resume accurate 1 step model, predict most likely state-action trajectories, and visualize them
- ~~See if multistep prediction problem is due to forwarding outside of training~~
- Count state visits
- ~~Reverse entropy to plan along well understood paths~~
