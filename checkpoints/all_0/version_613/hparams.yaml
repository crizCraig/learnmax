actions_per_batch: 8
avg_reward_len: 100
batch_size: 32
batches_per_epoch: 10000
beam_width: 3
checkpoint: null
data_dir: /home/a/src/learnmax/checkpoints
dvq_batch_size: 32
dvq_checkpoint: /home/a/src/learnmax/.lightning/learnmax-learn_max_experiments_bin/37yv98e9/checkpoints/epoch=8-step=85999.ckpt
dvq_enable_kmeans: true
dvq_enc_dec_flavor: deepmind
dvq_input_channels: 3
dvq_loss_flavor: l2
dvq_n_hid: 64
dvq_quantize_proj: 10
dvq_vq_flavor: vqvae
embedding_dim: 30
env_id: MontezumaRevenge-v0
gamma: 0.99
gpt_attn_pdrop: 0.1
gpt_batch_size: 7
gpt_betas: !!python/tuple
- 0.9
- 0.95
gpt_embd_pdrop: 0.1
gpt_input_embed: true
gpt_learning_rate: 0.0006
gpt_n_head: 10
gpt_n_layer: 8
gpt_resid_pdrop: 0.1
gpt_seq_len: 8
gpt_weight_decay: 0.1
n_steps: 1
num_search_steps: 10
num_state_embeddings: 256
num_workers: 0
pin_memory: false
salience_resume_path: null
should_overfit_gpt: false
should_train_gpt: true
should_viz_predict_trajectory: true
single_token2: false
train_to_test_collection_files: 10
use_internal_salience: true
warm_start_size: 10000
